{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the Gradient Descent Algorithm\n",
    "\n",
    "In this lab, we'll implement the basic functions of the Gradient Descent algorithm to find the boundary in a small dataset. First, we'll start with some functions that will help us plot and visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Some helper functions for plotting and drawing lines\n",
    "\n",
    "def plot_points(X, y):\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'blue', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'red', edgecolor = 'k')\n",
    "\n",
    "def display(m, b, color='g--'):\n",
    "    plt.xlim(-0.05,1.05)\n",
    "    plt.ylim(-0.05,1.05)\n",
    "    x = np.arange(-10, 10, 0.1)\n",
    "    plt.plot(x, m*x+b, color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and plotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJIMU3EVEMkjBXUQkg/4/1vMPymEmprEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c7c9d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv', header=None)\n",
    "X = np.array(data[[0,1]])\n",
    "y = np.array(data[2])\n",
    "plot_points(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Implementing the basic functions\n",
    "Here is your turn to shine. Implement the following formulas, as explained in the text.\n",
    "- Sigmoid activation function\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Output (prediction) formula\n",
    "\n",
    "$$\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + b)$$\n",
    "\n",
    "- Error function\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$\n",
    "\n",
    "- The function that updates the weights\n",
    "\n",
    "$$ w_i \\longrightarrow w_i + \\alpha (y - \\hat{y}) x_i$$\n",
    "\n",
    "$$ b \\longrightarrow b + \\alpha (y - \\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the following functions\n",
    "\n",
    "# Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    sigma = 1/(1 + np.exp(-x))\n",
    "    return sigma\n",
    "\n",
    "# Output (prediction) formula\n",
    "def output_formula(features, weights, bias):\n",
    "    output = sigmoid(np.dot(features, weights) + bias)\n",
    "    return output\n",
    "\n",
    "# Error (log-loss) formula\n",
    "def error_formula(y, output):\n",
    "    error = -y*np.log(output) - (1-y)*np.log(1-output)\n",
    "    return error\n",
    "\n",
    "# Gradient descent step\n",
    "def update_weights(x, y, weights, bias, learnrate):\n",
    "    y_hat = output_formula(x, weights, bias)\n",
    "    weights_updated = weights + learnrate * (y - y_hat) * x\n",
    "    bias_updated = bias + learnrate * (y - y_hat)\n",
    "    return weights_updated, bias_updated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.73105858  0.73105858]\n",
      " [ 0.88079708  0.88079708]]\n",
      "[ 0.73105858  0.95257413]\n"
     ]
    }
   ],
   "source": [
    "# Test above functions\n",
    "x = np.array([[1,1],[2,2]])\n",
    "y = np.array([0,1])\n",
    "print(sigmoid(x))\n",
    "\n",
    "w = np.array([1,1])\n",
    "b = np.array([-1])\n",
    "\n",
    "y_hat = output_formula(x, w, b)\n",
    "print(y_hat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function\n",
    "This function will help us iterate the gradient descent algorithm through all the data, for a number of epochs. It will also plot the data, and some of the boundary lines obtained as we run the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(44)\n",
    "\n",
    "epochs = 100\n",
    "learnrate = 0.01\n",
    "\n",
    "def train(features, targets, epochs, learnrate, graph_lines=False):\n",
    "    \n",
    "    errors = []\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "    bias = 0\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features, targets):\n",
    "            output = output_formula(x, weights, bias)\n",
    "            error = error_formula(y, output)\n",
    "            weights, bias = update_weights(x, y, weights, bias, learnrate)\n",
    "        \n",
    "        # Printing out the log-loss error on the training set\n",
    "        out = output_formula(features, weights, bias)\n",
    "        loss = np.mean(error_formula(targets, out))\n",
    "        errors.append(loss)\n",
    "        if e % (epochs / 10) == 0:\n",
    "            print(\"\\n========== Epoch\", e,\"==========\")\n",
    "            if last_loss and last_loss < loss:\n",
    "                print(\"Train loss: \", loss, \"  WARNING - Loss Increasing\")\n",
    "            else:\n",
    "                print(\"Train loss: \", loss)\n",
    "            last_loss = loss\n",
    "            predictions = out > 0.5\n",
    "            accuracy = np.mean(predictions == targets)\n",
    "            print(\"Accuracy: \", accuracy)\n",
    "        if graph_lines and e % (epochs / 100) == 0:\n",
    "            display(-weights[0]/weights[1], -bias/weights[1])\n",
    "            \n",
    "\n",
    "    # Plotting the solution boundary\n",
    "    plt.title(\"Solution boundary\")\n",
    "    display(-weights[0]/weights[1], -bias/weights[1], 'black')\n",
    "\n",
    "    # Plotting the data\n",
    "    plot_points(features, targets)\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting the error\n",
    "    plt.title(\"Error Plot\")\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Error')\n",
    "    plt.plot(errors)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the algorithm!\n",
    "When we run the function, we'll obtain the following:\n",
    "- 10 updates with the current training loss and accuracy\n",
    "- A plot of the data and some of the boundary lines obtained. The final one is in black. Notice how the lines get closer and closer to the best fit, as we go through more epochs.\n",
    "- A plot of the error function. Notice how it decreases as we go through more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2,) (100,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-90005167daac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearnrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-b30d617fa49c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(features, targets, epochs, learnrate, graph_lines)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Printing out the log-loss error on the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-7dc1019ee611>\u001b[0m in \u001b[0;36merror_formula\u001b[0;34m(y, output)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Error (log-loss) formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0merror_formula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2,) (100,) "
     ]
    }
   ],
   "source": [
    "train(X, y, epochs, learnrate, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
